[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Awash in Data",
    "section": "",
    "text": "Introduction\nThis book leads you through a few introductory lessons in data science. You can think of it as a self-guided textbook for teachers or students. If you’re a teacher, you might assign chapters, problems, or projects for students to read and do.\nIn this book, you will use CODAP, the Common Online Data Analysis Platform, to do your data analysis. CODAP is free and web-based, that is, it runs in your browser. You do not even need to sign in or make an account to use it."
  },
  {
    "objectID": "index.html#smelling-like-data-science",
    "href": "index.html#smelling-like-data-science",
    "title": "Awash in Data",
    "section": "Smelling Like Data Science",
    "text": "Smelling Like Data Science\nData Science is becoming a big deal in our society. It’s a hot profession with lots of well-paid jobs. Even if you are not a data scientist, data science is in your life. Every time you do a web search, get directions on your phone, or see a recommendation for a movie, a song, or a brand of ketchup, somebody did some data science to bring you that information. When you hear about the latest unemployment figures or the trends in income inequality, that comes from data science too. And when you hear people worry that some technological convenience will lead to greater surveillance and loss of privacy, once again, data science would make it possible.\nIt sounds like we had better learn about data science—but it must be super complicated, right? Data science involves huge data sets, and sophisticated computing techniques like machine learning and artificial intelligence. Doesn’t it take years of study—and buckets of talent—to learn that stuff?\nAs with anything, it does take years to be an expert. And experts may disagree about talent. But there are underlying ideas and ways of thinking that you can experience right now—and that’s what we hope this book will give you. We’ll use medium-sized data sets—at most a few thousand cases at a time, along with a few common-sense techniques, and a drag-and-drop data platform, to help you get an idea of what data science, for lack of a better term, smells like. When you’re done, you’ll be able to use that “sniff test” to recognize a data science problem; you’ll have a better idea what went into the data that you see and use, making you a more critical and competent citizen; and you’ll be better able to study data science in earnest, if you so desire.\nHow should we start?\nAnd even before that, what is data science, really?\nAs of the Spring of 2020, the COVID Spring, no one really knows. Everyone pretty much agrees that it lives somewhere in the borderlands between Statistics and Computer Science.\nWe can use our emerging sniff test to recognize it. We’ll use two main ideas:\n\nA data science problem often begins with a feeling of being awash in data.\nData science uses data moves to manipulate data.\n\nAwash in Data. This is a very touchy-feely thing to put in something about data science, but imagine: there is an ocean of data and you’re in a small boat, metaphorially trying to make your way. But you’re in a data storm; the sails are flapping madly and the waves are high. Data are coming in over the gunwales, threatening to swamp you. Emotionally, you might be excited by the challenge, or you might be terrified, wishing you were somewhere, anywhere else.\nIn a data science situation—especially as a beginner— you often don’t know what to do. You have way too much data, and the data you have is confusing. Even though you’re not literally in a boat, you are awash in data. This book, then, is about coping with “awash-ness”: developing skills and perspectives appropriate for doing data science. We will explore techniques for finding the patterns and stories in the ocean of data—for calming the seas and filling our sails.\nData Moves. These are techniques for coping with data in a data-science context. One example is filtering, that is, looking at a subset of your data. Looking at a subset lets you focus on one thing; it reduces the scope of the problem. It’s often a good way to take a step when you don’t know what to do. By reducing the amount of data and giving you an action to take, filtering reduces that awashness.\n\nA move like filtering is broader than the specific command you give a computer or what menu item to choose. It’s an underlying thing-to-do that is about manipulating the data. Throughout this book, we’ll use highlighted paragraphs like this one to draw attention to data moves when you do them; we hope that you will begin to recognize them for yourself, and develop the habit of asking, when things get confusing, whether filtering (or grouping, or summarizing or…) will move your investigation forward.\n\nBut there’s more! Data science is more than being awash and using data moves. Communication is a huge part of data science, and nothing is more emblematic of good data communication than a great visualization. Professional data scientists make amazing and dynamic graphics that communicate the stories behind complicated, huge datasets.\nWe will not do that here. We’re beginners, and there is plenty for us to do that uses graphs with the normal axes and points that students are aleady familiar with.\nWe have included a chapter about visualizations that describes CODAP’s graphing environment, shows some student work, and reflects on how to use data moves to make your graphics better."
  },
  {
    "objectID": "index.html#computers-coding-and-codap",
    "href": "index.html#computers-coding-and-codap",
    "title": "Awash in Data",
    "section": "Computers, Coding, and CODAP",
    "text": "Computers, Coding, and CODAP\nIt’s utterly impractical to do data science by hand. Data science deals with large amounts of data, so it’s no surprise that you will use computer technology to do this work. And although you can learn many things by reading, you will not really understand about being awash—and therefore you will not really understand data science—without using a computer to wrestle with the data yourself.\nThe vast majority of online introductions to data science begin by using a programming language, usually R or Python. These are languages used by professionals in the field, so it makes sense to use them when you are learning. If you are already proficient in coding, you could certainly start there.\nBut in this book, you will use CODAP.\nOne reason for that is that the activities here were designed for a four- or five-session introduction to data science at the high-school level. They assume no programming experience at all. Because CODAP is not a programmming language, there is no strange syntax to learn, nothing to configure, no libraries to download and install.\nIt’s a tradeoff, of course: there are many things you cannot do in CODAP that are possible when you code. Good coding also makes your work reproducible and reusable, recording every step of your analysis.\nStill, CODAP is a good place to start. It will let you experience data analysis and data moves with a minimum of overhead—and you will still do a great deal of computational thinking. Later, when you move into coding, you can focus on that, undistracted by the high winds and salt spray on that ocean of data."
  },
  {
    "objectID": "index.html#using-this-book",
    "href": "index.html#using-this-book",
    "title": "Awash in Data",
    "section": "Using This Book",
    "text": "Using This Book\nThis book is divided into parts, as you can see in the table of contents that probably appears in the sidebar on the left side of your screen.\nIf you are here to get an introduction to data science, or you’re about to teach it, you can work sequentially through the Lessons part, referring as necessary to other parts of the book. The Data Portals part describes some of the widgets we have developed to let you get your hands on some interesting data. We put instructions about those portals in their own chapters in order to shorten the text in the lessons.\nThe second part, Data Moves, is more substantial, and contains some of our thinking about what makes data science data science. If you are designing data science curriculum, you might want to read this part.\nFinally, CODAP Topics explains some of CODAP’s underlying model, as well as some more esoteric aspects of the platform and its relationship to data science.\n\nUsing CODAP for lessons and examples\nTo do work on a problem in the book, or to try out an example, there are two ways to open up CODAP and start working:\n\nLook for the CODAP icon. Then use the link to open up a new tab or window in your browser. You will need to switch back and forth between the instructions in the book and the CODAP window.\n\n\n… You’ll see data on 800 children and teens.\n\nOften, it’s even easier: you can do the work in a live illustration, a CODAP window embedded in the book itself. This makes things very easy—no switching back and forth—but it has the disadvantage that you may need more screen space for your graphs and tables.\n\n\n\n\n\n\n\nWarning\n\n\n\nThere’s a “gotcha” here if you’re using a tablet such as an iPad. If you try to drag something—and you drag things a lot in CODAP— you may find that the whole document scrolls instead. It’s really annoying. There is a solution, though: press on the thing, and then wait just a beat before starting to move. You’ll get used to it quickly.\n\n\nHere is an example, showing the incomes of a bunch of employed Californians in 2013. You can see their marital status, too. Try dragging Gender to the vertical axis of the graph:\n\n\n\n\n\nCan I just use my phone?\nNo. It will work, but the screen really is just too small."
  },
  {
    "objectID": "01-lesson-part.html#overview",
    "href": "01-lesson-part.html#overview",
    "title": "Lessons",
    "section": "Overview",
    "text": "Overview\nThe first “Part” of this book—the next few chapters—contains lessons and assignments for a quick introduction to data science. I created these lessons for students in a high school, as part of a class called “Applied Mathematics,” which includes a number of topics including consumer-ish math. This introduction occupied a couple of weeks of class time, roughly four seventy-five minute blocks. Although the students varied widely in their level of preparation, they were generally polite, attentive, and well-intentioned.\nWe ran this most recently in the Spring of 2020, under quarantine, when the class was “virtual,” run over Zoom. The lessons here roughly parallel what we did in class that time, when students were isolated in their homes and groupwork was possible, but harder than “before.” The discussion suggestions in the lessons work fine, but not as well as in an in-person classroom. Therefore I think these lessons might also work, with sensible modifications, for self-study. For example, you will not be turning in your projects—unless you want to send them to me; I’d love to see them!\nLikewise, if you are a teacher with a class of your own, of course you should modify what you see here so that it makes sense for your students and your situation. For example, our school uses Google apps extensively, so students all know about setting permissions and submitting links to Google docs via email. In previous years, I had insisted that students make pdfs and email those in. What works for you depends on your situation.\nYou may want to modify assignments, add new ones, skip others. Go for it. I will try to describe, here and in the commentary that accompanies each element in this Part, my rationale for the order and content I chose.\nClass preparation: We (the teacher-of-record and I) set up a Google doc as a “landing page” for the class. It had material that students would need: links to class-specific instructions, links to the CODAP software and to this book, as well as links to various data sets. Before each class, we edited the doc so that today’s most important links were at the top, with an agenda of what we would do. That way, all past links and agendas were still in the document, at the bottom, in reverse chronological order.\nFor the first lesson, for example, we had a link to this book and to a blank CODAP document, with advice to bookmark the page. We also had a link to an “800 children and teens” document, which we easily got to in the first session.\nThose data links are also embedded in this book, so if your students use this book (for ours, this was just a resource), or you are doing self-study, there’s no need to make an extra set of links."
  },
  {
    "objectID": "01-lesson-part.html#the-getting-started-lesson",
    "href": "01-lesson-part.html#the-getting-started-lesson",
    "title": "Lessons",
    "section": "The “getting started” lesson",
    "text": "The “getting started” lesson\nHere is a link to the lesson chapter\nCritical links:\n\na blank CODAP document, https://codap.concord.org/app\nthis book https://codap.xyz/awash\n\nThis introduces CODAP basics, especially how to make graphs. This takes students only a few minutes, and, as the commentary suggests, could even be homework.\nIn an actual classroom, circulate and make sure that everybody has found the relevant page and can make graphs. Lead a brief discussion as suggested in the commentary."
  },
  {
    "objectID": "01-lesson-part.html#children-and-teens-part-one",
    "href": "01-lesson-part.html#children-and-teens-part-one",
    "title": "Lessons",
    "section": "800 children and teens, part one",
    "text": "800 children and teens, part one\nHere is a link to the lesson chapter\nAdditional critical link:\n\nage and height data: http://codap.concord.org/app#shared=31797\n\nThe dataset has information about 800 USA-ians, aged 5 to 19, from a national health survey (NHANES). The attributes (a.k.a. variables) include age, gender, height, weight, armspan, upper arm length, and pulse. We will eventually focus on age, gender, and height—but we don’t tell students that at first.\nEventually, we focus on how height changes with age—and how it also depends on gender. That presents a problem that often makes students feel “awash”: they have three attributes but only two axes on a graph. The obvious solutions—multiple graphs, color the points—don’t work out very well.\n\nFiltering. We show students a different approach, using a data move: filtering. We look at only a small part of the data, just the 10-year-olds (where the girls are taller!). Then it’s easy to compare the boys and the girls in a graph, now that age is not a factor.\nGetting to the filtering is the critical part of the lesson, and sets up the groupwork described in that chapter: each group does this filtering move for different ages, pooling the class data so students can enter and plot the mean ages for each gender at each age. For logistics, we created a shared Google sheet where students entered the means."
  },
  {
    "objectID": "01-lesson-part.html#a-first-assignment",
    "href": "01-lesson-part.html#a-first-assignment",
    "title": "Lessons",
    "section": "A First Assignment",
    "text": "A First Assignment\nHere is a link to the assignment\n\nNew link—Census data: https://codap.concord.org/app#shared=22176\n\nThis assignment introduces a new dataset from the US Census. It has income data for 1000 25-to-44-year-olds, along with gender (of course) but also race, Hispanic status, and educational attainment.\nThe assignment asks students to explore the data, and then to come up with a claim and a graph to address the claim. This should be simple—simple enough that they could conceivably do the data analysis using the live illustration embedded in the assignment.\nThis assignment is written so it’s entirely done in CODAP (no Google doc at this point), so it can be done and turned in in class (although some students might not finish). It could even be done orally, though we did it as an assignment to turn in.\nMany students will use this dataset to compare incomes, and that will often lead into social justice issues. We love that kind of topic, and students are often intrigued and motivated that they are exploring it with real data about real people."
  },
  {
    "objectID": "01-lesson-part.html#children-and-teens-part-two",
    "href": "01-lesson-part.html#children-and-teens-part-two",
    "title": "Lessons",
    "section": "800 children and teens, part two",
    "text": "800 children and teens, part two\nHere is a link to the lesson chapter\n\nGrouping and summarizing. This chapter introduces grouping cases in the dataset by reorganizing the table and summarizing those groups by calculating summary (or aggregate) values, in this case, mean heights. These are our second and third core data moves. Conceptually, it’s the most subtle—and powerful—part of this intro to data science. Your goal, as a teacher, is to get as many students as possible to understand this.\n\nThe session may begin with the students entering the mean heights by gender and age that they worked on in groups. They can then make the summary graph. If they made this graph already (e.g., in the previous session), remind them of it.\n\nRemind students that that process used the filtering data move.\n\nNow students will learn how to have the computer do all that. This is perfect for a demo. Get their close attention and go through it slowly, sometimes backing up as students have questions. There are two main parts: making the groups; and then making the aggregate calculation. The text in the chapter has all sorts of questions embedded in it; use them to guide how you show students this technique.\nYou will probably end the session debriefing the first assignment (with the Census data) and previewing the second one."
  },
  {
    "objectID": "01-lesson-part.html#a-second-assignment",
    "href": "01-lesson-part.html#a-second-assignment",
    "title": "Lessons",
    "section": "A Second Assignment",
    "text": "A Second Assignment\nHere is a link to the assignment\nThis is a more complex version of that first assignment. Notice these differences:\n\nLogistical issues:\n\nIt’s supposed to be a Google doc, not just a CODAP doc. (If you want a different format, go ahead!)\nStudents put a link to their CODAP doc in the Google doc.\nThey need to learn how to get a graph into the Google doc.\nIf possible, they should use that grouping move they just saw, and, in addition, calculate summary values for the groups.\n\nThey need to enhance their investigation and give it more nuance. We refer to this in the text as “dig deeper.”\nThey need to pay more attention to communication, for example in the size and choice of their graphics and the coherence of their narrative.\n\n\nStudents may be perplexed about what we mean by “dig deeper.” An early section in the chapter contains an example of the kind of thing they could do—exploring the obvious issue of income disparity between males and females—and then shows what “digging deeper” might look like.\n\nThe other difference is that we restrict the topic: We give them just two claims to choose from. Most students become invested in the Census data. It’s engaging, and quickly brings social issues into math class. But they need an alternative; ours is data from BART, the Bay Area Rapid Transit. There are links in the assignment to orient you and those students to the data.\n\nThe next class session\nIn our most recent class, some students “got” this assignment and were done in a flash. For others, the whole grouping-and-aggregation thing was alien and complex. That’s not surprising: it is conceptually the hardest part of this unit.\nSo you cannot expect students to have completed even this simple task by the beginning of the next session. We devoted pretty much the whole session to working on this task, giving students help individually and in small groups, and getting them to help each other.\nFor students who were moving faster, we presented the “small project” task (below) and let them get started. It might be better, however, to give them other useful things to do. In an in-person class, these students could be resources for their peers, or we could have given them other enriching problems to solve. There are some in this book (xxx) that were not available at that time."
  },
  {
    "objectID": "01-lesson-part.html#a-small-project",
    "href": "01-lesson-part.html#a-small-project",
    "title": "Lessons",
    "section": "A Small Project",
    "text": "A Small Project\nHere is a link to the assignment\nThis is the capstone project for this unit, and is really just a small extension beyond the second assignment students have just completed.\nThe key differences are:\n\nStudents pick their own topics.\nThey can use the more extensive, national Census data that includes different states and different years.\nFor students using BART data, they can play the embedded “secret meeting game.”\n\nSome consequences are:\n\nStudents might be more invested in the topics because they chose them themselves.\nThey will have ideas for other things they want to do with the data.\n\nSome will be too hard, and students may need to find alternatives.\nSome will be possible, but may not have been covered in class.\n\n\n\nLinking. As an example of this last possibility, some students, independently, wanted to connect the Census data to data that wasn’t in the data set, that is, to link our data to external data. That’s another data move we call joining, so we’ve added a chapter about it even though it’s not really part of a simple introduction to data science.\nHere is a link to that chapter"
  },
  {
    "objectID": "01.20-teens.html#exploration",
    "href": "01.20-teens.html#exploration",
    "title": "3  800 Children and Teens, part one",
    "section": "3.1 Exploration",
    "text": "3.1 Exploration\n\nYour first task is to explore the data. Here are some questions you can address:\n\nWhat attributes do you expect to be related?\nCan you show that relationship in a graph?\nWhat other relationships can you show?\nTry making more than one graph, and then select points in one of them. What happens? How might that be useful?\nWhat do you think the units are for these values? (especially Weight, Height, and Pulse)\nWhat’s BMI? If you don’t know, look it up."
  },
  {
    "objectID": "01.20-teens.html#a-specific-question-who-is-taller",
    "href": "01.20-teens.html#a-specific-question-who-is-taller",
    "title": "3  800 Children and Teens, part one",
    "section": "3.2 A Specific Question: Who is Taller?",
    "text": "3.2 A Specific Question: Who is Taller?\nWho is taller, males or females?\nStereotypically, we probably agree that, in general, males are taller. But is that really true? Let’s use the data to find out.\nThe next illustration contains a CODAP document that graphs Height against Gender. That’s the obvious way to look at our question.\n\n\n\nIt looks as if the pile of males is a bit higher up in the graph, that is, they’re taller. But how much? Let’s find the mean.\n\nOh, and if you’re reading this book in a browser, that illustration is live. You don’t have to make a separate CODAP window for this bit.\n\n\nClick on the graph to select it.\nAt the right of the graph, click on the “ruler” icon. A panel opens up. We call these things “palettes.”\nClick the checkbox for mean. (Of course you can try other options as well.)\nHover over the mean lines that appear. You can see the values.\n\nYou should find that the average height of males is about 10 (cm) greater than the average height of females. So that shows that our preconception (males are taller) is correct.\nBut, but…\nIf you stop and think a bit, our graph is deeply bogus. It’s a bad analysis. Why?\nTry not to read ahead…\n\nIf you’re a student in a class, discuss with your group.\nIf you’re studying alone, think about this before scrolling down to see what we think."
  },
  {
    "objectID": "01.20-teens.html#making-the-question-more-specific",
    "href": "01.20-teens.html#making-the-question-more-specific",
    "title": "3  800 Children and Teens, part one",
    "section": "3.3 Making the Question More Specific",
    "text": "3.3 Making the Question More Specific\nThe problem is that we haven’t taken Age into account, and Age is much more important than Gender in determining height. The whole long tail of short people—for both males and females–is made up of little kids. If you’re not convinced, drop Age into the middle of the graph.\nGo ahead, we’ll wait.\n\nIn general (the graph says), the short people are younger. Make sure you can explain how the graph shows that. What is it about the colors that says short people are younger?\n\nStill, it’s a confusing graph. Let’s make it simpler.\nInstead of looking at everybody we have, ages 5–19, let’s just look at one age: 10-year-olds. First we’ll filter the graph so it shows only 10-year-olds. Then we’ll compare the heights of those boys and those girls.\nYou get a fresh, live document below. Follow these steps for the filtering:\n\nDrag Age to the horizontal axis so you have a graph of Height against Age.\nTake a moment to discuss (or reflect) on whether that graph makes sense. It tells a story. What is it?\nSelect all the 10-year-olds. Do this by dragging a rectangle around those points. If this is unfamiliar to you, you can probably figure it out by messing around. If that doesn’t work for you, get help!\nWith the graph selected, click on the “eyeball” palette on the right to bring up a menu.\nChoose Hide Unselected Cases. Aha! Now the graph has only 10-year-olds.\n\n\n\n\nNow figure out how to compare the heights of the boys and the girls, this time of only the ten-year-olds. Be sure to put the mean on the graph so you get their average heights. See if you can get this graph:\n\n\n\n\n\nHeights of ten-year-olds, split by gender.\n\n\nSome questions to answer; if you don’t know, don’t be afraid to ask others!\n\nHow did you compare the 10-year-old girls to the boys?\nAre there other ways to compare them in a graph? Sure there are!\nWhich way works better?\nThe heights of females overlap with heights of males. What does that mean?\nWhat are the mean heights of the 10-year-old girls and boys?1 How did you find them?\nFor the whole dataset, males are taller. For 10-year-olds, females are taller. How is that possible? Does it fit with your experience?"
  },
  {
    "objectID": "01.20-teens.html#groupwork-getting-all-the-means",
    "href": "01.20-teens.html#groupwork-getting-all-the-means",
    "title": "3  800 Children and Teens, part one",
    "section": "3.4 Groupwork! Getting all the means",
    "text": "3.4 Groupwork! Getting all the means\nIf you’re in a class, and there is enough time, your instructor will break you into groups.\nEach group will be responsible for a couple of ages. For each age, do what we just did for 10-year-olds: find the mean height for the girls and the boys at that age. Then enter your data on a class table, which may be on a whiteboard, or perhaps online in a shared table such as a Google Sheet.\nThen, when all the groups are done, enter your data into a fresh CODAP document. How do you do that?\n\nBegin with a fresh CODAP document.\nMake a new table (look in the Tables tool).\nCreate the relevant columns (what columns do you need?).\nEnter the data by typing the numbers in to the table cells.\n\nIf you have the data in a Sheet, you could, instead:\n\nBegin with a fresh CODAP document.\nExport the sheet as a .csv file. (in Google, it’s in the File menu. Choose Download and then Comma-separated Values.)\nDrop the file into your CODAP document.\n\nThen plot the means as a function of age. Make sure you can tell the males from the females!\n\nPlotting two things at once\nIf the mean heights for males and females are in different columns in your table, you might first plot the females on the vertical axis and age on the horizontal. But then, if you plot the males in the normal way, the female data will disappear. How do you get them both on the same graph?\nThe trick is this: as you are dragging the males in, wait. With the mouse down, pause and look: there is a gray outline of a plus sign at the top of the axis. Drop the attribute there instead of on the axis; it will add the data to the plot instead of replacing it."
  },
  {
    "objectID": "01.20-teens.html#commentary",
    "href": "01.20-teens.html#commentary",
    "title": "3  800 Children and Teens, part one",
    "section": "3.5 Commentary",
    "text": "3.5 Commentary\nThere are three main phases to this lesson.\n\nFirst, students mess around with the data, making graphs using any attributes they like, looking for relationships. Ideally, a few of them get to show and explain their graphs, and you run a discussion as decscribed in the commentary.\nIn the second phase, we focus on a specific issue: who is taller, females or males? We learn to show means on the graph. When the obvious analysis doesn’t work well, and we are still awash in data, we get even more specific and focus on 10-year-olds. We use a data move, filtering, to do this. Very important.\nIf possible, there’s a third phase where students—probably in groups— find the mean heights for boys and girls at each age, then plot those results.\n\nThe final graph tells a clear story about height and gender and age.\n\nWho is taller? More detail…\nIn the first, exploratory phase, somebody probably made a graph with height and age or height and gender. Explain that we will now focus on this issue.\nIn a class—even online—rather than having students read the instructions and do this alone or in pairs, I do this next part as a demo, and go through the process outlined in the text. I focus on height versus gender, with questions along the way (e.g., Why is height on the vertical axis? Because it’s the response? Right. But also, because height is vertical.)\nI make the graph and show how to put the means on the graph using the ruler palette. We see, by hovering, the different values. We ask, “Are we done? Males are taller than females?”\nAnd if no one says so, we tell them that actually, there is something deeply bogus (or hinky or whatever the current term is) about our graph. It’s a fine graph, but it’s unfair. Why? What’s missing?\nWait time. Wait time.\nSomeone will say “age.” Probe for what they mean. Plop Age onto the graph to see the color gradient. Yeah, the tails are all little kids.\nEarlier someone might have made the graph of Height against Age. You can refer back to it, and make that graph for the class. If they haven’t, you can do it, plopping Gender into the middle.\nWhat do you think about this graph? Is it clear what’s going on? Partly, but it’s hard work to read this graph. It’s still confusing. Let’s find a way to have this make more sense.\nSo we do the filtering move: we select the 10-year-olds and hide the rest, then put Gender on the axis and show the mean heights of each group, reflecting on the realization that, although in general the males are taller, the story is different for particular ages.\nThat’s about as much lecture/demo as we can tolerate, so we switch to a different mode.\n\n\nGroupwork! Getting the means in more detail…\nWhat if we did that procedure—looking at only the ten-year-olds, and recording the mean heights of the males and females— but for every age?\nIt would be really cool. So we do exactly that. Every group gets an age or two to be in charge of. Their task is to find the mean heights of males and females at those ages. Groups post the means in a table on the class whiteboard or in a Google Sheet.\n\n\n\n\n\n\nGroups post mean heights in a Google Sheet.\n\n\n\n\n\n\n\nValues from the sheet, plotted in CODAP.\n\n\n\n\n\n\nThe fact that it was groups gave students a welcome break, a chance to talk, and also reinforced that key skill of filtering. When we were in quarantine, we did this in randomized Zoom breakouts. We had pre-assigned the ages to group numbers.\n\n\nIn addition, this part of the activity gave students practice with computing means; introduced how to enter your own data into CODAP; and most importantly showed them where you can go with this.\n\nI think it’s important that the filtering and typing will be slow and a little laborious, for two reasons: first, of course, when you show them how the computer can do it in the next lesson, they will see how cool and time-saving it is. Second, slowing down highlights this idea of turning the means into values in a table that you can graph. It gives it time to sink in.\n\n\nThe key moment: filtering\n\nFiltering is our first data move. When we display all the data, the Heightvs.Age graph does make sense, and it tells a story, but it’s complicated. Looking at it, we’re pretty “awash in data.”\n\nFor example, we were trying to compare heights across genders, right? But the height-age graph doesn’t have gender (left-hand illustration). What if we drop Gender onto the middle of the graph? You’ll get something like the right-hand illustration (and you should do it yourself).\n\n\n\n\n\n\nHeight by age, no gender.\n\n\n\n\n\n\n\nSame, with Gender. This is confusing. We’re awash.\n\n\n\n\n\nYou can kind of see that males are taller, at least older males are taller, but it’s not really clear because so many of the points are stacked on top of each other. You can’t tell whether purples are hiding under oranges or what.\nBut when we filter, and look at only the 10-year-olds, everything is clearer. Looking at that graph, we are no longer “awash.” It’s all manageable.\n\n\n\n\n\nHeights of ten-year-olds, split by gender (again).\n\n\n\nThe dots are not hiding each other any more.\nThere are fewer dots altogether.\nIt’s a normal kind of graph, a kind we might be more used to reading.\n\nOr, more deeply, this graph reduces the dimensionality of the problem. Before the filtering, we really needed to show three attributes at once: Height, Age, and Gender. But our graph has only two dimensions.\nBy focusing only on the 10-year-olds, we eliminate the Age attribute: it’s now irrelevant because everybody we’re looking at is 10 years old. That means we can use that horizontal, Age axis for Gender instead.\nWe’re still interested in age—after all, it has a big influence on height— but we have decided to ignore it, temporarily, strategically. We used the filtering data move to help us be less awash, to help us see something familiar.\nThat familiarity can also be an inspiration for what to do next, for how to “dig deeper” into the data."
  },
  {
    "objectID": "01.50-assignment-2.html#how-do-you-know-when-youre-done",
    "href": "01.50-assignment-2.html#how-do-you-know-when-youre-done",
    "title": "6  A Second Assignment",
    "section": "6.1 How do you know when you’re done?",
    "text": "6.1 How do you know when you’re done?\nYou have a Google Doc (or whatever format your instructor requires). It contains:\n\nYour name.\nA simple claim. Pick one:\n\nPeople with more education make more money than people with less education.\nPeople who get on BART at SFO generally get off at Powell Street.\n\nA graph with the first-look, obvious results.\nA description of why that simple approach might not be enough to really explain the data\nA description of what you did to further the investigation (“dig deeper”). In this description,\n\nYou have grouped the data by dragging an attribute (or attributes) to the left in the table.\nYou have calculated some summary value (e.g., a mean or a sum) for each group by making a new column with a formula.\n\nThe results of that deeper investigation (with, e.g., a new graph of the data)\nA conclusion: is the story any different now?\nPossibly, ideas for additional “dig deeper” activities with this data set, and…\nA link to a shared CODAP doc (like last time) so the instructor can see what you did.\n\nYour Google Doc is probably no more than two pages long. Be sure to set permissions so your instructor has edit access.\n\nWhere to get the data\nInstead of using a “canned” data set, for this assignment you will use a data portal. In CODAP, this appears as a window where you specify what data you want, and then press a button to get it.\n\n\n… BART is a regional transit system in the San Francisco Bay Area. SFO is the San Francisco International Airport. You can read all about the BART data portal in a separate chapter.\n\n… You can get data on education, income, race, gender, etc., and choose how many cases. Go to the options tab to choose what attributes you want.\n\nACS stands for “American Community Survey,” which is run by the Census Bureau, and collects data between the decennial Census years. The portal for the Census data looks like this:\n\n\n\nACS data portal. Notice how we have requested 1000 people and have selected EmplStatus (employment status) as an attribute.\n\n\n\n\nElaborations\nGoogle Doc. If you do not know yet how to make a Google Doc, it’s time you learned. If you need to know more, ask a friend or Google it.\nIncluding a Graph. How do you get the graph from CODAP into your file? At the moment (early 2020), you can’t just copy and paste. Here are two alternatives:\n\nClick the camera palette in the graph and…\n\nchoose Export Image (you can also Open in Draw Tool).\nchoose Local File and pick where you want to save the file.\nafter saving the file, import it (it’s in .png format) or do a copy/paste into your Doc.\n\nUse a screen-capture utility to get an image of your graph, and then paste it into your doc.\n\nPro tip: Be conscious of space. Noobs often just paste huge graphs into their documents and leave them that way. After pasting, shrink the graph so that it’s a reasonable size. What’s reasonable? When you print it out, it should still be easy to read any text. For a typical CODAP graph, that’s no bigger than about 1/6 of a page. If you know how to wrap text around a graphic, sometimes that can look very professional."
  },
  {
    "objectID": "01.50-assignment-2.html#gender-and-income",
    "href": "01.50-assignment-2.html#gender-and-income",
    "title": "6  A Second Assignment",
    "section": "6.2 Example: Gender and Income",
    "text": "6.2 Example: Gender and Income\nHere’s an example of the kind of thing we have in mind:\nSuppose we were interested in gender and income. The simple approach is to (duh) plot gender and income. The graph alone looks vaguely like the men get more, but if you put the median on the graph, and rescale it, it’s really obvious:\n\n\n\nTotalIncome split by Gender, with lines showing median income for each group.\n\n\nThis is what we probably expect: men earn more than women. If we look at median values, men earn $17,000, versus $9,200 for the women. But does that tell the whole story? How could we dig deeper? (…as required in the assignment)\nWe might ask:\n\nIs it possible that the incomes really are equal, but we’re looking at it wrong?\nCan we be more nuanced? For example, is there some other factor that affects income?\n\nLooking at the graph, see the large number of people who seem to earn zero—or close to it? That spike at zero is taller for women. Maybe that’s because more women work in the home, and are not paid.\nSo maybe the incomes for people with jobs are equal between men and women, but because more women do not get paid, their median income is lower overall. This reasoning is an example of exploring whether we’re looking at it wrong, and that there is another factor—employment—that affects income. That is, it’s not just gender.\nTo test this idea, let’s just look at people with jobs. It turns out that we can get data for an attribute (a column) called EmplStatus for “employment status.”\n\nThat means you could filter to focus your investigation on people with jobs. That way, you can explore whether men with jobs generally earn more than women with jobs.\n\nTry that in the live illustration below. The “employment status” attribute is at the far right of the table.\n\n\n\nYou should find that the men still earn more. If you hide everyone but those that are “Civilian employed,” the men earn $45,000 to the women’s $30,000. So the fact that more women do unpaid work does not completely explain the difference in income.\nNotice that this will only work if you have downloaded EmplStatus data. If you get partway through your investigation and realize that you wish you had downloaded something else, or something more, you can’t add additional columns to the cases you already have. But remember: starting over is free. Just go back and get fresh data with the attributes you want."
  },
  {
    "objectID": "01.50-assignment-2.html#dont-forget-to-drag-left",
    "href": "01.50-assignment-2.html#dont-forget-to-drag-left",
    "title": "6  A Second Assignment",
    "section": "6.3 Don’t forget to drag left!",
    "text": "6.3 Don’t forget to drag left!\nWe’ve seen what we mean by “dig deeper,” but don’t forget to read the assignment. It also expects you to do that “drag left” grouping move. In this case, that would be dragging Gender left to make groups of males and females. Then you would make a new column (maybe called medInc) in which you would calculate the median income for each gender.\nLook back at the section where we made groups by age if you don’t remember how.\nThen think about how you can use grouping to help with your “dig deeper” work.\n\nWhen you drag Gender to the axis of a graph, CODAP helps you do a grouping data move. Then, when you put the median on the graph, that’s summarizing. For this assignment, though, we want you to make those moves explicitly—grouping by dragging left, summarizing in a new column with a formula— because (a) it’s good practice and (b) it’s more flexible."
  },
  {
    "objectID": "01.50-assignment-2.html#digging-deeper-philosophy-section",
    "href": "01.50-assignment-2.html#digging-deeper-philosophy-section",
    "title": "6  A Second Assignment",
    "section": "6.4 “Digging Deeper” and skepticism",
    "text": "6.4 “Digging Deeper” and skepticism\n“Digging deeper” means adding nuance to your investigation, bringing out important trends and effects that might not be obvious at first. It’s like fleshing out a sketch and making it more detailed.\nBut it’s also about being skeptical. When you make an initial, obvious graph, and draw some conclusion or make some claim, a skeptic steps back and wonders whether that’s really correct. Is there some other explanation for what you are seeing?\nYou can think of this as a “yes, but” attitude. It’s also the role of a “devil’s advocate”—someone whose job is to tear down an argument. If the devil’s advocate succeeds, that’s good, because without that skepticism, the conclusion would have been wrong. And if the devil’s advocate fails, that’s good too, because by passing that test, the original conclusion is stronger.\nSkepticism is not always confrontational, however. You can also think of it as a “yes, and” attitude: the claim may be right as far as it goes, but there may be other important considerations.\nIn the case of gender and height, we saw that, indeed, males were generally taller than females, but only after about age 13."
  },
  {
    "objectID": "01.50-assignment-2.html#commentary",
    "href": "01.50-assignment-2.html#commentary",
    "title": "6  A Second Assignment",
    "section": "6.5 Commentary",
    "text": "6.5 Commentary\nYour job as a student is to try really hard to understand the bit about dragging left to make groups, and making new columns with calculations. If you’re feeling challenged enough already, pick the claim about education and income.\nHere’s some advice for how to explore and get comfortable:\n\nMake a graph, any graph. Try different groupings: drag one attribute left, and see what happens. Then drag the first one back and then try a different one.\nTry making a group (like for education) and adding an additional attribute (like gender) to the left. See what groups exist now.\nSelect groups on the left by clicking in that row. See what gets selected in the graph.\nWhen you make a column and give it a formula, try different formulas and see what happens.\nRemember that the name of your “formula” column is just a name. It’s not the formula. So if the column is named MeanIncome and the formula is median(income) you will get the median. (You should change the name!)\nChange what’s on the graph. Make more graphs! Try graphs with a calculated attribute on an axis.\n\nOh and:\n\nTry dragging TotalIncome to the left and see why that’s a terrible idea.\n\nIf you just mess around for a while like that, you will probably see something that addresses your claim. You may even have created something that will be perfect for your “dig deeper” section.\nTwo last key pieces of advice:\n\nWhen you make a grouping or summarizing move, stop for a moment and be sure you understand what changed. What does the organization of the table mean now? What are the groups? How did the numbers change? What does this one particular number mean?\nDon’t beat yourself up if you still feel a bit “awash.” This is surprisingly complicated, especially if you have more than one attribute on the left. It takes time. You will get it.\n\n\nQuestions and Claims\nIn many school statistics (or science) projects, you begin by posing a “research question.” In this case, the question might be, “who earns more—women or men?” It will come as no surprise that the answer is “men.” That’s what we have heard about our society today (or in 2013, when the data were taken). So “who earns more” might seem to be a silly question.\nInstead of a question, sometimes it makes more sense to make a “claim.” This is a statement about what may be true, that you are going to investigate. Our claim might be, “men earn more that women.”\nFor this assignment, we gave you a claim, so you don’t have to worry about making one up. But think about other claims you might make about your data (after all, in the next assignment you get to pick your claim), or how your claim might change as you dig deeper and add nuance to your analysis.\nIn stating your claim, you might also want to say why you think your claim is true. It’s great to have a reason for your claim, but be careful: In most cases for this unit, you won’t have data that will tell you anything about the reasons behind some effect.\nFor example, you might say that you believe people with more education will earn more because they are qualified for higher-paying jobs. Your data can tell you whether they earn more—we have data about education level and income— but we don’t have any data about the educational requirements of the jobs they have.\nIt’s fine to include reasons if you have them, but keep any claim about your data separate from the reasons just as we did above. Here’s how to do it wrong:\nI claim that people with more education are better-qualified for high-paying jobs, and as a result they earn more.\nSee how that’s different? You can’t make a graph about job qualifications. Keep it separate, even if the separator is just the word “because.”"
  },
  {
    "objectID": "03-datamove-part.html#and-two-more",
    "href": "03-datamove-part.html#and-two-more",
    "title": "Data Moves",
    "section": "And two more",
    "text": "And two more\nAs I suggested in the introduction, data moves are not all there is to data science. You’ll find two more chapters bundled with the data moves listed above, in their own chapters:\n\nPreparing and cleaning data\nIn this book, students use data we provide, or data they choose from data portals. When you bring in your own data, it’s often “unruly.” That requires a whole new set of skills.\n\n\nVisualization and communication\nThis is a giant topic to which we cannot do justice. Still, there are a few things that need to be said."
  },
  {
    "objectID": "03.30-Calculating.html#a-simple-example-unit-conversion",
    "href": "03.30-Calculating.html#a-simple-example-unit-conversion",
    "title": "10  Calculating and Recoding",
    "section": "10.1 A simple example: unit conversion",
    "text": "10.1 A simple example: unit conversion\nYou have a bunch of data about the heights of children and teens. The problem is that the Weight attribute is measured in kilograms. For some reason, your audience will not understand this new-fangled metric system, so you decide to make your graphs in pounds instead.\nThe basic plan is simple: create a new column, give it a name (e.g., WtLb), and then give the new column a formula (Weight * 2.2). Here’s the step-by-step; try it out in the live illustration below.\n\nBe sure the table is selected.\nClick the gray circle with the plus sign near its upper right. A new column appears for the new attribute. Its name is selected, ready for entering.\nType the new name: WtLb. Then press enter to complete the edit.\nClick on the new name. A menu appears. Choose Edit Formula….\nIn the formula box, enter Weight * 2.2 and press Apply. Notice that the formula you enter is only the part to the right of the equals sign.\n\n\n\n\nNow you can change the graph to WtLb by dragging the new attribute name to replace the old one.\nSmall extra: Notice that WtLb has no units in parentheses. Let’s fix that.\n\nClick WtLb just like we did to get the formula editor.\nThis time, choose Edit Attribute Properties… Notice what we have here. Cool stuff.\nEnter pounds in the unit box.\nPress Apply. Shazam! The units appear!\n\n\nFathom aficionados from the ancient years will justly lament the loss of units arithmetic. Good old Fathom actually knew the conversions."
  },
  {
    "objectID": "03.30-Calculating.html#recode-numeric-to-categorical-section",
    "href": "03.30-Calculating.html#recode-numeric-to-categorical-section",
    "title": "10  Calculating and Recoding",
    "section": "10.2 Making Numeric Attributes Categorical",
    "text": "10.2 Making Numeric Attributes Categorical\nYou can use formulas to convert numerical attributes to categorical. Suppose you’re investigating income, but graphs with income on them quickly become complicated: they stretch over a wide range and they’re badly skewed.\nSo for exploratory purposes, you’d like to divide the population into two groups:\n\nThose making $40,000 or more, which you will label \"$$\", and\neverybody else, which you will label \"$\".\n\nHere’s how to do it; use the example live document below.\n\nWith the table selected, click the gray circle with the plus sign to make a new attribute.\nGive it a good name (e.g., money) and press enter to complete the edit.\nClick the new name to get the menu, and choose Edit formula….\nIn the formula editor, enter if(TotalIncome >= 40000, \"$$\", \"$\"). Press Apply. The column should fill with values. Don’t leave out the quote marks!\nMake a graph that uses your attribute. For example, put EmplStatus on one axis, and then plop money into the middle. Aha! Employed people are more likely to be in the $$ group!\n\n\n\n\nNotice how that if() function works. It’s like the one in most spreadsheets, and takes three arguments. Consider this formula for an attribute called kindOfPet:\nif(sound = \"woof\", \"dog\", \"cat\")\n\nThe first is a “Boolean” expression, either true or false.\nThe second is what you get if the expression is true (the pet is a dog).\nThe third is what you get if the expression is false (the pet is a cat).\n\nUse money as you would any attribute. You can use it to make graphs, and you can use it in other calculations.\n\n\n\n\n\n\nGotcha! (still true, May 2023)\n\n\n\nHowever: If you drag money to the left to make groups—a perfectly reasonable thing to do—CODAP will not do what you want. Why not? CODAP tries to apply that formula to the entire group (as it would median(TotalIncome)) and it can’t because there are many different values of TotalIncome in the group, so it can’t tell what value to assign to money.\nTherefore, before you drag, click on the column header, and in the menu that appears, choose Delete Formula (Keeping Values). Now the money column—filled with $$ and $—is just as if you had typed in every value separately.\nJust be aware: now, if you change someone’s TotalIncome, their money value will not change, because you deleted the formula. Similarly, if you import more data, there is no formula to fill in new values for money."
  },
  {
    "objectID": "03.30-Calculating.html#recoding-categorical-section",
    "href": "03.30-Calculating.html#recoding-categorical-section",
    "title": "10  Calculating and Recoding",
    "section": "10.3 Reducing the number of categories in a categorical attribute",
    "text": "10.3 Reducing the number of categories in a categorical attribute\nSometimes, a categorical attribute has many categories, and you want to group them together. With States, for example, you might want to group them by “region,” so you would put California, Oregon, and Washington into a region called “Pacific,” and so forth for the rest of the states.\nLet’s practice this skill with something simpler, using the data we just used above. We are going to reduce the six categories in Education to two categories: collegiate, which means they went to college at all, and no college, which means they never did.\nWe could make a formula, but it would be ugly and complicated. Instead, we will simply type the new values in.\nWon’t that take a long time? We have 1000 cases! No, because we’ll type them only once. Do this using the live illustration below:\n\nDrag Education left to make (six) groups by education level. Select the table.\nClick the “left” gray circle (the “add attribute” circle), just above and to the right of Education. This makes a new column.\nName it college.\nIn that column, enter the appropriate values for each category. That is, double-click the cell and actually type collegiate or no college. You can use Copy and Paste if you like.\nYou have now re-coded Education so that the “improved” values are in college. You no longer need Education to make your groups, so drag it back to the right. Now you have only two groups (the college groups) on the left.\n\n\n\n\nYou can use this new attribute as you would any other:\n\nMake a graph with Gender on the horizontal axis.\nPlop college into the middle of the graph.\nIn the “configuration” palette (below the ruler palette on the graph), choose Fuse Dots Into Bars.\nHover over the bars; what do you learn from the percentages that appear?\n\nAlso,\n\nMake a graph of TotalIncome with the new attribute, college, on the other axis. A useful, telling graph! Stay in school, kids…"
  },
  {
    "objectID": "03.30-Calculating.html#by-the-way-always-make-a-new-column",
    "href": "03.30-Calculating.html#by-the-way-always-make-a-new-column",
    "title": "10  Calculating and Recoding",
    "section": "10.4 By the way: Always make a new column!",
    "text": "10.4 By the way: Always make a new column!\nThis is a practice you should ingrain into your data-analysis muscle memory: Avoid destroying data.\nSeems obvious, but the techniques we mentioned here sometimes lead students into that trap.\nSo: When you’re recoding Education into anyCollege, you might be tempted to (do not do this!):\n\nDrag Education left to make six groups be education level.\nEdit graduate, bachelor's, and some college to be collegiate.\nEdit the rest to be no college.\n\nDo you see the problem? You have overwritten the original data. Suppose, later, you decide you want your collegiate group to be only people who have finished a bachelor’s degree? You no longer have anyone with some college to move from one category to the other.\nTherefore, leave the original data as it is, and put any new data in a new column. Then if you change your mind, you don’t have to start over."
  },
  {
    "objectID": "31-other-cool-tools.html#simmer",
    "href": "31-other-cool-tools.html#simmer",
    "title": "34  Other cool tools",
    "section": "34.1 Simmer",
    "text": "34.1 Simmer\nSimmer was originally designed as a probability simulation tool where you program it using a block-programming interface (à la Scratch, in fact based on the Blockly library from Google).\nSo, for example, if you wanted to simulate rolling two dice and adding, you might write this program:\n\n\n\n\n\nThis will result in a CODAP table with 36 cases with suitable random values in the die1 and die2 columns.\nClick here to go to the simmer documentation"
  },
  {
    "objectID": "31-other-cool-tools.html#arbor",
    "href": "31-other-cool-tools.html#arbor",
    "title": "34  Other cool tools",
    "section": "34.2 Arbor",
    "text": "34.2 Arbor\nArbor lets you construct and analyze classification trees. These are very interesting alternatives to traditional graphs that work well whenever you’re trying to sort cases into two groups.\nOne good context is medical: you’re trying to diagnose patients as sick or well. But there are other great contexts such as spam detection, as in, based on the subject line of an email, can you tell if it’s spam or not?\nHere’s another: what characteristics of Titanic passengers are associated with survival? Here is an arbor tree made with that data:\n\n\n\n\n\nThe tool will also let you make a confusion matrix (the familiar 2x2 table) of your diagnoses and see a mosaic plot of that information.\nFor a lot more about trees, click this link for the arbor guide.\nAs you will see, that guide is also an online resource for a 2023 paper from Teaching Statistics."
  },
  {
    "objectID": "07-stats-part.html#whats-in-stats-101",
    "href": "07-stats-part.html#whats-in-stats-101",
    "title": "Statistics, Data Science, and CODAP",
    "section": "What’s in Stats 101?",
    "text": "What’s in Stats 101?\nFor the purposes of this section, when I say “statistics” I will mean “the contents of the introductory statistics course.” That’s an important distinction because many Real Life Statisticians actually do data science in their everyday work: they use computational tools and deep thinking abut data to find the stories hidden in vast amounts of data.\nBut you are probably either a student in an introductory course—in data science or statistics—or a teacher in such a course. Or you may even be associated with a computer science course such as APCSP. In any of these cases, the contents of the course may be more relevant for this discussion.\nSo: what’s in Stats 101?\nStereotypically, it starts with “descriptive statistics” and then moves on to “inferential statistics.” It also usually includes some “modeling.” Let’s look at these elements.\nModeling can mean many different things in different contexts. A mathematical model is typically a simplification of reality. Reality is complex and messy, but if we make a good model, we can learn about the simplified situation and apply that understanding to reality, for example, by making predictions. These predictions won’t be perfect, but they can be pretty good.\nBut how do we make a good model? In a stats class, one task might be to look at points on a scatter plot and make a linear model, that is, find a line that approximates the data as well as possible.\nThere are various techniques for doing this; a famous one is least-squares regression, which gives you the (deceptively-named) “line of best fit.”\nDescriptive statistics includes making a variety of graphs that show one or two variables, and making summary calculations. These summary calculations tend to be measures of center such as the mean and the median, and measures of spread such as the standard deviation and the interquartile range. The summaries also include proportions such as the percent of light bulbs that are defective.1\nThese numbers lead to getting more comfortable with distributions of data. Students learn to identify and reason about the shape, center, and spread of distributions, and to identify and cope with outliers.\nThe overall idea is to be able to make graphs and calculations in order to draw conclusions about data. Students use graphs and summary values to address claims and answer questions about the situation that gave rise to the dataset.\nAnd if that sounds kind of like what we’ve been doing all along, you’re right. Data science has a lot in common with descriptive statistics, but with bigger datasets and, importantly, more variables. The sheer size of modern datasets leads to that “awash” sense and the need for more computation (and data moves) in order to cope.\nInferential Statistics is different. You can think of it in many ways; here are two:\n\nYou use it to draw conclusions about a population from a (sometimes small) sample.\nYou use it to decide if some difference you observed is “real,” that is, whether it might have arisen by chance.\n\nLet’s illustrate the population/sample situation with a prototypical task: polling.\nTwo candidates, Grunt and Flaky, are running for Senate. You do a poll of 100 people and 55 support Grunt. In fact, 5,000,000 people will be voting. Will Grunt win?\nThe obvious answer is, Grunt will get 55% of five million votes; we expect Grunt to win 55 to 45.\nBut will Grunt get exactly 55%? Of course not! The 100 people we asked were only a sample. Even the very best sample—a random one—will not precisely mirror the population (the five million voters). Randomness will throw it off. This sampling variation could result in our getting “too many” or “too few” Grunt voters in our sample.\nSo the question is, how confident are we that, having gotten 55 out of 100 randomly-chosen voters, Grunt will get more than 2,500,000 in the election?\nNow let’s consider another situation. The illustration shows the height distributions of boys and girls aged 11 and 17.\n\n\n\nGender differences in height. Left: age 11; right: age 17.\n\n\nIt’s really obvious that at age 17, the boys are taller. More precisely, it’s obvious that the mean height of the boys is greater—individual boys may be quite short, and individual girls can be taller than most boys.\nBut at age 11, it’s not as clear. For this set of data, the girls have a higher mean. But is that just because of the particular girls we have data for, or is this a “real” difference?\nIn all of the situations we’ve just looked at—the polling and the two height comparisons—the underlying question is really, could the difference we observe “plausibly” arise by chance?\nIn the case of the 17-year-olds, the answer is no. For the 11-year-olds, it seems plausible: maybe there’s really no (mean) height difference between the boys and the girls. For the Grunt/Flaky poll, it’s not obvious either way. It looks good for Grunt, but with a bigger poll, we might see Flaky pull ahead.\nMost of the second half of an introductory statistics course is all about questions like these. You learn a number of techniques for addressing these issues. And all of them are related to probability."
  },
  {
    "objectID": "07-stats-part.html#what-part-of-that-is-important-for-introductory-data-science",
    "href": "07-stats-part.html#what-part-of-that-is-important-for-introductory-data-science",
    "title": "Statistics, Data Science, and CODAP",
    "section": "What part of that is important for introductory data science?",
    "text": "What part of that is important for introductory data science?\nLet me re-issue this caveat: This is the opinion of a single author, and is subject to a lot of rethinking and revision.\nBut here are three “stats” things I think would be worth covering in an introductory data science course.\n\nSample size and stability\nSummary values (a.k.a measures, a.k.a. statistics) are more stable the larger the sample.\nIn the polling example, we might wonder, “Suppose I had taken a different sample of 100 voters. How different would the result have been?” We can make a simulation to answer that question. We can then change the size of the poll—the N—and see what that does.\n\n\n\n\n\n\nAn aside\n\n\n\nIf you were simulating Grunt and Flaky, what probability would you use for assigning a voter to Grunt? An obvious answer is 55%, until you stop and realize that 55% is the result of the poll, not the true, underlying probability of a voter voting for Grunt. That’s exactly what we don’t know! The sneaky trick we use is to simulate using 50%, pretending there is no difference between Grunt and Flaky, and seeing how often you get 55% in spite of that.\nLater, you might use a variety of “true” probabilites and decide over what range of probailities 55% is plausible. That’s called a confidence interval.\n\n\nI think it’s important that students build intuition about how poll results might vary. The most important realization is that the percent that will vote for Grunt will vary less the larger the poll is. That’s what I mean by stable.\nWhen you study statistics (or science) you’ll find out that the spread of the results goes down as the square root of N. But for now, a basic intuition is more important: If your data shows that the median income for Chilean-Americans is greater than the median income for whites in general, don’t take it too seriously if you have only two Chilean-Americans in your sample.\n\n\nPlausibility and chance\nFor the most part, looking at a graph (like the one above with heights) is enough to tell you whether some difference is important.\nBut once in a while, you need to check using inferential techniques.\nIn a stats course, you will learn various techniques that apply in different situations. But they all ask and answer the same question: If there were no difference, how likely is it that this difference would arise by chance? If it could happen reasonably often, we’d say it’s plausible. If it would be rare—depending how rare—we’d call it implausible; and as a shorthand, we might say the effect is “real.”\nIn introductory data science, it’s worth learning this basic idea and learning to apply it. But here you will not learn the many varied techniques. You’ll just learn two.\nThe first is to simulate “binomial” situations and use those simulations to reason about some underlying proportion or probability. Polling is such a context: there is an underlying proportion (the proportion of Grunt voters) and we pull a number of values at random (100 poll participants). By simulating many times, we learn how varied poll results can be, and how that spread depends on the sample size.\nA second technique is randomization. We ask, is there an association between gender and height? To decide, we artificially break any association by scrambling the values of Gender and computing the difference in means. By re-scambling many times and re-computing that difference, we learn whether the “true” unscrambled value would be unusual if there were no association.\nRandomization is for assessing the association between two variables. What about estimating some parameter of one variable, like the mean rainfall in a city? For that we can use a technique (and a CODAP plugin) called the bootstrap. This is the “randomization” equivalent of the confidence interval.\nMastering those two will set you up to understand the rest when the time comes.\n\n\nHow good is your model?\nModeling is a third area that a budding data scientist should address.\nModeling has many facets, but right here, I’m talking about using a function to approximate data. We use models in order to make predictions and to understand some underlying principles.\nImagine a scatter plot with a more-or-less linear swath of points. We want a good model, in this case, a line, that approximates the pattern we see. But what makes a model good?\nThe first part of that answer is that the line or curve you propose should have about the same shape as the data. It should have some of the same properties, too. For example, if the data are curved, you probably shouldn’t be satisfied with a line.\nAnother example: if the data are distances, they can never go below zero. So if your model is a function that goes below zero, it might not be a good model.\nSometimes it’s hard to decide if messy or zoomed-out data are curved or not, or, more generally, if the curve is the same shape as the data. In that case, it often helps to plot the residuals from the model in order to see if there is some underlying pattern you want to account for.\nThe second part of the answer is that you want to make your model pass close to the points.\nTo figure out how close the model is, create a measure of goodness of fit—a number, a statistic—that tells us how good the model passes to the data. At its crudest, the measure is the sum of the distances of all the points from the line. 2\nThen you change the line until that number is as small as possible. In that case, the line is as close as it can be to the points.\nBut what do you change? For a line, you can change the slope and the intercept, the m and b in y = mx + b. Those are two parameters that determine the line. So the trick is to figure out, of all possible values of slope and intercept, which ones give the smallest measure of goodness of fit.\nIf you use least squares, you can use calculus to figure that out. But for an introduction to data science, your eyeball can do a pretty good job. You’ll use sliders to vary the parameters and just look and see.\nThe key underlying idea is that of the measure itself."
  },
  {
    "objectID": "07.30-bootstrap.html#thinking-through-bootstrapping",
    "href": "07.30-bootstrap.html#thinking-through-bootstrapping",
    "title": "27  Randomization and Estimation: the Bootstrap",
    "section": "27.1 Thinking through bootstrapping",
    "text": "27.1 Thinking through bootstrapping\nSuppose you measure the weights of 10 capybaras and you find that their mean weight is 47 kilograms. If these capybaras are a suitably random sample of all capybaras, what can you say about the mean weight of all capybaras?\nClearly our best guess is 47 kilos as well. But will it be exactly 47 kilograms? Of course not. Capybaras vary in weight, and there’s no way we accidentally, randomly, got 10 capybaras that were perfectly representative of the whole species.\nThe big question is, how far off of the population mean is the mean of our single sample likely to be?\nTo find out, we do something that kinda sorta smells like what we did with randomization tests and scrambling.\nHere’s the plan:\nWe write the weights of all ten capybaras on chips and put them into a bag. Then we draw out ten chips, record the numbers, and find the mean. However, we put each chip back after we draw it. That is, we are sampling with replacement. This is called a “bootstrap sample.”\nBecause we put them back every time, we’ll probably get some duplicates. Similarly, some of our capybaras won’t be represented in a particular bootstrap sample. Therefore the means we get won’t be exactly the same as the mean of our “real” sample. Some means will be larger, some smaller, depending on which chips we pulled.\nWe will do this many times, and then look at the distribution of means in order to assess how far off our single-sample mean is likely to be."
  },
  {
    "objectID": "07.30-bootstrap.html#bootstrap-tangerines",
    "href": "07.30-bootstrap.html#bootstrap-tangerines",
    "title": "27  Randomization and Estimation: the Bootstrap",
    "section": "27.2 Your first bootstrap: Trader Joe’s tangerines",
    "text": "27.2 Your first bootstrap: Trader Joe’s tangerines\nWe don’t have measurements of capybaras, but we do have one bag of 18 Trader Joe’s tangerines, measured by students at Lick-Wilmerding High School in San Francisco in 2017.\nThese data appear in a live example below, with a graph of the weights, also showing the mean, which is a little under 53 grams.\n\nMake a new column called meanWeight and compute the mean of weight. It should be 52.94 g.\nNow we want to get the bootstrap plugin. As of May 2023, it is not in the Plugins menu, so we will do the following:\n\nChoose Import… from the hamburger menu.\nClick URL and enter https://codap.xyz/plugins/bootstrap/ into the box.\nClick IMPORT. The bootstrap plugin appears.\n\nbootstrap will complain that it needs a measure. You have one: meanWeight! Drag it to the left.\n\nYou are ready to strap on your boots. Your workspace should look something like this:\n\n\n\n\n\nPress the 1x button to do a single bootstrap resample. A new dataset appears, called measures_basic tangerines with one value of the mean under the meanWeight column (on the right). It will probably not be the same value as the original, which makes sense.\n\n\n\n\n\n\nOne measure. My first bootstrap mean was 52.98.\n\n\n\nGraph meanWeight. Collect more samples. They should center roughly around the true mean, 52.94.\nKeep collecting so you have a total of 200.\n\nThis distribution should be pretty symmetrical, and centered on the original mean.\nThink about what each point represents: a mean of 18 values drawn from a distribution equal to that of the real data. That is, if all groups of TJ tangerines are statistically the same as the 18 in our bag, each one of these values is a possible mean.\n\n\n\n\n\n\nYou could look at the samples…\n\n\n\nTo see the last bootstrap sample,\n\nGo to the Tables menu.\nChoose bootstrapSample_basic tangerines\nGraph weight and compare it to your original data. Can you see the holes? The duplicates?\n\n(We did this when we scrambled the heights of 13-year-olds)\n\n\nAll of the means in our graph are possible, some values are more likely. We have 200 values; let’s find the “middle” 90%. We will exclude 10 cases on either end of the distribution.\n\nIn the ruler menu/palette, press Movable Value and Add twice. You now see a range.\nAlso in the ruler, check Count and Percent.\nMove the values to get as close as you can to 10 (or 5%) in each tail.\n\nYou should have a graph more or less like mine:\n\n\n\n\n\nWith this technique, we have created what I call a 90% “plausibility interval.” My best guess for the mean weight of all Trader Joe’s tangerines is 52.94 grams. But I would not be at all surprised if it were anywhere in the range from 52.11 to 53.84. If somebody gave me a bag of 18 tangerines, and their mean weight was 55, I would think that maybe they were from another store, or that maybe TJ had changed supplier (since 2017, almost certain!), or something else that made these new tangerines systematically different from the ones in the original bag.\nNow notice, looking back at the original data, that a single tangerine of 55 grams is not surprising at all! Here are the two graphs together, scaled the same:\n\n\n\nBelow, in blue: the original data. Above, in tangerine: mean weights from 200 bootstrap samples.\n\n\nThis makes some kind of sense. Looking at the original data graph, we see that if we pulled a 55-gram tangerine out of a TJ bag, chances are good that most of the other 17 will be lighter.\nWe could spend a great deal of time right here on why the distribution of means is so much narrower than the distribution of the original data. But that is the province of a more formal stats class.\nIt does, however, speak to our goal of developing a taste for stability. The tangerines have a weight range of about 53 ± 4 grams, but a bag of 18’s mean is within about 53 ± 1 gram. The mean of a large sample is stable in a way that the individual data are not.\n\n\n\n\n\n\nDanger! Do not overstep!\n\n\n\nAll of the caveats we made in the scrambling chapter apply here as well.\nFor example, it is wrong to say that there is a 90% chance that the true mean falls in the range we described above.\nAll we can say is that if our bag is perfectly representative of the distribution of all tangerines, then samples of 18 drawn from that same distribution will have means in that interval about 90% of the time.\nGot that? It’s easier just to say that it’s plausible that the true mean is in the interval. How plausible? You’re 90% confident.\nIf you need something more official, learn about confidence intervals, but even then, watch out: they don’t mean what people often think either!"
  },
  {
    "objectID": "07.30-bootstrap.html#commentary",
    "href": "07.30-bootstrap.html#commentary",
    "title": "27  Randomization and Estimation: the Bootstrap",
    "section": "27.3 Commentary",
    "text": "27.3 Commentary\nThe one most important thing?\nWith real data, the numbers you calculate or measure are uncertain. Therefore, always consider reporting a range rather than a single number.\nThe Big Dogs are getting better and better at this. Polling results, for example, almost always have a margin of error.1 But how do you display that in a graph? There are a number of choices, none of which are easy to do in CODAP. But you can read about then on this interesting site from PBS about using data in news reporting.\nThe next thing:\nThat uncertainty (generally) goes down as your sample size increases. More people in your sample, more tangerines in your bag, the more certain you are about averages or other calculated values such as sums, proportions, medians, etc.\nCorrespondingly, if you break a sample down into groups, each group is smaller than the whole, so the group uncertainty is inevitably larger (i.e., worse) than the whole sample’s uncertainty.\n\n27.3.1 How close is our plausibility interval to a real confidence interval (CI)?\nYou can calculate a CI and compare.\n\nBring up a CODAP document with a plausibility interval, such as the one you made for tangerines, earlier in this chapter.\nMake a 95% plausibility interval, that is, make each tail 5%. If you have 400 samples, that’s 10 cases in each tail.\nIn the original data file, you have already computer the mean. Make three new attributes; let’s call them CI (for the half-width of the interval), low for the lower bound (which is the mean minus CI), and high for the upper bound (mean plus CI).\nThe value for CI is 1.96 times the standard error, so the formula would be 1.96 * stdErr(weight) if you’re doing tangerines.\nCompare your movable values with low and high.\n\nMy graph and table look like this:\n\n\n\nBy the way: the movable values’ percentages are listed as 3%. But we know they’re each 2.5%. CODAP doesn’t do parts of percents in the percentage display…but that’s also why it’s important to show the count."
  },
  {
    "objectID": "07.60-tangerines-redux.html",
    "href": "07.60-tangerines-redux.html",
    "title": "29  Tangerines Revisited",
    "section": "",
    "text": "We saw data on tangerines in the chapter on bootstrapping, but we didn’t see all of the data. The more complete dataset has 72 cases and three attributes:\n\nid\n\nThe initials of the student who “owned” the tangerine\n\nweight\n\nThe weight of the tangerine in grams\n\nday\n\nWhich day of the lesson this measurement was taken\n\n\nThat’s right, we have repeated measurements over the course of a week. What do you suppose happens to the weight of a tangerine as time passes?1\nNow, what to do? First, we will concentrate only on day 0 and day 2, so that’s 36 cases in two groups. If you plot the two distributions of weight, you see this:\n\n\n\nWeights and means for 18 tangerines on day zero and day 2. Notice that we have made day categorical in the graph.\n\n\nThis presents one clear task:\n\nDo a randomization test (i.e., scrambling) to see if it is plausible that the difference in mean weights could be due to chance alone. Find a \\(P\\)-value and draw a conclusion.\n\nBut then, there is a different task we can do to approach this problem from another direction\n\nEstimate (i.e., use a bootstrap) the mean difference in weight of the 18 tangerines between day 0 and day 2.\n\nThat is,\n\n\n\n\n\nDifferences for 18 tangerines\n\n\n\nCalculate, for each individual tangerine, how much weight it gained or lost. (You will have to do a grouping move. But what should you group by?)\nPlot those gains or losses to make sure they make sense. Author’s results at right.\nFind the mean of those values.\nDo a bootstrap to find a plausible range for that mean.\nDoes the range overlap with zero? (no!)\nExplain what that must mean.\n\nThen compare your two results.\nYou can\n\nor you can do your work in the live demo below.\n\n\n\nYou should have discovered that the “paired” version, where you looked at the 18 differences from individual tangerines rather than the overall difference in the distribution of 18 tangerines, was much more obviously not due to chance.\nSee if you can make sense of this. Of these two statements:\n\nIt is obvious that the distribution of differences does not overlap zero.\nIt is obvious that the means of the two distributions are different.\n\nWhy is (a) so much more obvious?\nResearchers often use this idea of a “paired” test when they can, especially in a situation like this (which is called “repeated measures.”)\nSuppose you have a drug that’s supposed to reduce cholesterol. If you have two ways of analyzing the data:\n\nFind the reduction (or gain) of each individual in the study before and after they take the drug, and find the average of the changes.\nFind the mean cholesterol for the group before and after they take the drug, and find the change of the averages.\n\nYou will usually find a stronger result with the first (paired) scheme. Again, see if you can figure out, conceptually, why.\nNow, as to where the data science is: think about the different ways you had to arrange the dataset in order to get what you were looking for. Some of this was about knowing CODAP and how to “drive” the program. But part is also your conceptual understanding of how a dataset works and the power of grouping.\n\n\n\n\n\nThis is a science question, really, which means that the best answer is often, “it depends.” To which we ask, “depends on what?”, which makes it a data question again.↩︎"
  },
  {
    "objectID": "04.30-screen-space.html#shrink-your-table",
    "href": "04.30-screen-space.html#shrink-your-table",
    "title": "17  Screen Space",
    "section": "17.1 Shrink your table",
    "text": "17.1 Shrink your table\nWe want to see all the data at once, and for some reason, we seem to think that making the table as large as possible is the way to do it. There are two things wrong with this: first, in a data science context, there’s usually way too much data to see this way; and second, looking at a table is (usually) a terrible way to see all the data. That’s why we have graphs.\nSo the first soution to your lack of screen space is to shrink your table.\nThe problem with that is that you still need to see the attribute names—the column headings—in order to drag them to graphs.\nTherefore, make your tables wide but short. You probably need to see only a row or two of the data in order to remember what kind of values are in which columns.\n\n\n\n\n\n\nLeft: a big table.\n\n\n\n\n\n\n\nRight: a short table—there’s room for work!"
  },
  {
    "objectID": "04.30-screen-space.html#case-card-view-section",
    "href": "04.30-screen-space.html#case-card-view-section",
    "title": "17  Screen Space",
    "section": "17.2 Case card view",
    "text": "17.2 Case card view\nIf you have a lot of attributes, even if your table is wide, they might not fit on the screen. That means you’re constantly scrolling back and forth to get to the attributes you want.\nYou might need case card view. It’s an alternative to the table that shows you the values for one case, but oriented vertically instead of horizotally. Often, this takes up much less space than the table, and shows you more attributes.\n\n\n\nUsing the case card view: even more room for work.\n\n\nTo get case card view,\n\nclick the little icon in the table’s upper left corner. Try it in the live illustration below.\nThen change the analysis. For example, drag Marital and plop it in the Age graph (replacing N_Married) to see how marital status is related to age."
  },
  {
    "objectID": "04.30-screen-space.html#minimizing-and-renaming-components",
    "href": "04.30-screen-space.html#minimizing-and-renaming-components",
    "title": "17  Screen Space",
    "section": "17.3 Minimizing and renaming components",
    "text": "17.3 Minimizing and renaming components\nIn the upper right of every component—table, graph, text object, map, whatever—you’ll see an X and a big minus sign. The X lets you delete the component, of course. The minus sign lets you minimize it, that is, shrink it so only its title bar shows. Click the minus sign again to make it full size.\nTry that on the components in the illustration in the previous section.\nOf course, if you have a bunch of minimized things you can’t tell them apart…or can you?\nClick once on the title of a component to select the title; then you can edit it to be anything you want. This can be a good practice, especially if you are preparing graphs for a presentation. You can name your graph something like “how education relates to employment” instead of “people.”"
  },
  {
    "objectID": "04.30-screen-space.html#the-tiles-menu",
    "href": "04.30-screen-space.html#the-tiles-menu",
    "title": "17  Screen Space",
    "section": "17.4 The tiles menu",
    "text": "17.4 The tiles menu\nSuppose you have a lot of graphs, and you can’t find the one you want. Even if you’ve given them names, it can be hard. Maybe they’re overlapping, or even scrolled off the screen.\nNo problem! Use the little-used Tiles menu near the upper right of the screen. It shows you a list of all of your components. Not only that, but all you have to do is hover over a title, and the component pops to the front so you can see what it is\n\n\n\nThe tiles menu shows all of your components."
  },
  {
    "objectID": "04.30-screen-space.html#using-choosy",
    "href": "04.30-screen-space.html#using-choosy",
    "title": "17  Screen Space",
    "section": "17.5 Using choosy",
    "text": "17.5 Using choosy\nChoosy is a very sweet tool that you can find in the Plugins menu.\nIt does a number of things, but the one that’s important here is that it makes it easy to hide attributes. You know how you can use hide or set aside to hide rows in a table (a filtering data move)? Choosy lets you hide columns, which is a lifesaver if your dataset has lots of attributes.\nFor more about choosy, see this guide."
  },
  {
    "objectID": "04.40-graphing-tips.html#palettes-section",
    "href": "04.40-graphing-tips.html#palettes-section",
    "title": "18  Graphing Tips",
    "section": "18.1 Palettes",
    "text": "18.1 Palettes\nIf you click on a graph, a blue-green panel appears on its right with some icons on it. Clicking on one of those reveals a menu-like palette of additional tools."
  },
  {
    "objectID": "03.70-visualization.html#codap-graphs-in-general",
    "href": "03.70-visualization.html#codap-graphs-in-general",
    "title": "14  Visualizing and Communicating",
    "section": "14.1 CODAP graphs in general",
    "text": "14.1 CODAP graphs in general\nIn a graph, by default, CODAP represents each case as a dot.\nAs we mentioned up in the commentary for the summarizing data move, CODAP is oriented to individual cases that are “atomic” bits of data, for example, people in a Census, or moments of time in a record of some phenomenon. So dots are pretty good representations.\nEvery graph has, basically, two axes. When you put an attribute on an axis, each dot moves so that its location corresponds to its value for that attribute.\nIf the attribute is numeric or a date, the axis has numbers or dates, and CODAP centers the dot on that value. If the attribute is categorical, CODAP places the dot in a bin labeled by the categorical value. By separating the dots into bins, CODAP is grouping them: categorical plots give you a data move for free.\nIf you plop an attribute into the middle of a graph, the points color depending on the values of that “legend” attribute. That gives you a kind of third dimension in your graph, which you can use to show additional relationships, or to emphasize one of the attributes on an axis.\nPeople seem to understand all of that intuitively, and it gets them pretty far. But there’s more."
  },
  {
    "objectID": "03.70-visualization.html#codap-graphing-tips",
    "href": "03.70-visualization.html#codap-graphing-tips",
    "title": "14  Visualizing and Communicating",
    "section": "14.2 CODAP Graphing Tips",
    "text": "14.2 CODAP Graphing Tips\nThe next few sections describe some of the features of CODAP graphs that you might not find on your own.\n\n14.2.1 Palettes\nBlue-green palettes are attached to the right side of a graph. There is a vertical array of icons; each one has a number of controls or choices inside it.\nPalettes also appear when you select a table, a map, or a slider. We’ll describe those features here as well, even though this chapter is about visualization.\nThe palettes appear only when the graph or table is selected. That is, there is only ever one set of palettes on the screen at a time.\n\n\n\n\nicon\n\n\ndescription\n\n\n\n\n\n\n\nRescale tool. Press to show all points or rescale column widths.\n\n\n\n\n\n\n\n“Eyeball” palette. In a graph, use it to show or hide points.\nIn a table, use it to set cases aside.\n\n\n\n\n\n\n\n“Ruler” palette. In a graph, display summaries (e.g., means, percents, standard deviation).\nIn a table, make new attributes or export data.\n\n\n\n\n\n\n\n“Paintbrush” palette. Change the appearance of points in a graph. Control color, stroke, and size.\n\n\n\n\n\n\n\n“Snapshot” palette. Take a picture of the graph, and then export that picture. Edit the picture first if you wish in the Draw Tool.\n\n\n\n\n\n\n\nConfiguration palette. In a graph with a numeric axis, bin the data. Where appropriate, fuse dots into bars.\n\n\n\n\n\n\n\nTrash can. In a table (only), delete cases.\n\n\n\n\n\n\n\n\n\n\nGotcha!\n\n\n\nYou will frequently select cases, i.e., select points in Graph A, and then want to use the eyeball tool in graph B. If you just click in Graph B, however, you may change or eliminate the selection of points! The solution is to click on Graph B’s title bar. Then the selection from Graph A is preserved.\n\n\n\n\n14.2.2 Re-ordering categoricals\nIf you make a graph with a categorical attribute, by default CODAP orders the alphabetically. Sometimes, this is maddeningly unhelpful!\nIn many cases, the solution is quick and easy: grab the categorical value by the name, and drag it where you want it.\nxxx add example\n\n\n14.2.3 Fusion Power: Bar charts\nIf you have made a categorical graph, you can change the default “dot” display into a bar chart, which may be more familiar.\nAlso, sometimes, when you have created summary values (such as the means of something for several groups)), it may be effective and appropriate to display those aggregate values as bars.\nMake bars using the “configure” palette  and choose the option Fuse Dots into Bars.\nxxx add example\n\n\n14.2.4 Showing data directly as bars\nxxx\n\n\n14.2.5 Histograms\nHow do you make a histogram in CODAP? You might expect (correctly) that you will fuse dots into bars at some point, but first you need to bin the data.\n\n\n\n\n\n\nNote\n\n\n\nI am making a distinction here between bar charts and histograms. We just made bar charts when we fused dots with categorical values. Notice that they had spaces between the bars.\nIn a histogram, the data are numerical, and there is no gap between the bars.\n\n\nThe live illustration below has 1000 heights of people between 25 and 35 years old. We want to make the dot plot into a histogram. Do the following:\n\nSelect the graph and open the configuration palette \nChoose Group into Bins.\n\nThe graph adjusts into bins; notice that each bin is 10 cm wide.\n\nAgain in the configuration palette, choose Fuse Dots into Bars.\n\nNow you have a histogram! Use the configuration palette to experiment with the other controls, such as the bin width.\n\n\n\nYou would think that if you put Gender on the vertical axis, that it would split the histogram. But as of May 2023, you will only get the binned version—not fused. Still useful, though!\n\n\n14.2.6 Connecting lines\nxxx add example"
  },
  {
    "objectID": "03.70-visualization.html#student-graphs-and-commentary",
    "href": "03.70-visualization.html#student-graphs-and-commentary",
    "title": "14  Visualizing and Communicating",
    "section": "14.3 Student graphs and commentary",
    "text": "14.3 Student graphs and commentary\n\n\n\nA student graph about mobility.\n\n\nThis graph leaves us in an “awash” state. It does show the data, and a careful reader can figure out some patterns, but it’s too busy, too complicated, too much work for the reader to understand what’s going on. As a good communicator, you want your audience to get your message as easily as possible. Sure, you want them to think, but you want them to start thinking already seeing what you see in the data.\nSo consider two things we could do about it. One is to turn dots into bars, and leverage the legend. The other is to make some a new summary attribute or two, and plot those.\n\nNotice that both choices involve grouping and summarizing. The bars-and-legend version gives you one plausible graphic scheme for free; yet the DIY choice—making attributes—is more flexible, though for the moment it limits you to dots.\n\nxxx more examples in the hopper\nxxx include facet splitting, earlier in this chapter"
  }
]